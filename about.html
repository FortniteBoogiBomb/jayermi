<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>About</title>
    <!-- Link to your CSS file -->
    <link rel="stylesheet" href="style.css">
</head>
<body>
    <!-- Header section -->
    <header>
        <h1>Jay's Website</h1>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="extra.html">About</a></li>
                <li><a href="https://github.com/FortniteBoogiBomb">Visit my GitHub profile</a></li>
                <!-- Add more navigation links as needed -->
            </ul>
        </nav>
    </header>

    <!-- Main content section -->
    <main>
        <h2>About Page</h2>
        <p> Hi there! I'm Jay I am 23 years old and just graduated from Indiana University</p>
        <p>I have a Bacholer of Science in Intellegent Systems Engineering, with a concentration in Computer Engineering</p>
        <p>I have been programming with C & Python for 4+ years, and I have extensive experience with MATLAB and microcontrollers  </p>
        <p>I have experience with many other languages and embedded systems, as well as robotics and drones</p>
        <p>Below you can download my resume using the button<p>                                                                   
        <button class="download-resume-button"><a href="Jay Ermi Resume.pdf" download>Download Resume</a></button>
        <h2>Capstone</h2>
        <p>One of the more signifigant projects that I have worked on as an Engineer was my desnior design capstone project</p>
        <p>Our prototype was called the EMG controlled exo-skeltal arm brace </p>
        <img src="images/IMG_2949%20(1).jpg" alt="Picture of brace hardware, I designed and assembled this hardware prototype myself" class="my-image">
        <h2>Research</h2>
        <p>---Trusting Ai---</p>
        <p>During my Junior year I took two classes, (one first semester and one second semester)</p>
        <p>Taught by Dr. Greg Lewis. After taking both of these classes which I thoroughly enjoyed </p>
        <p>I approached Dr. lewis and asked if he needed any help in his lab. He was very excited that I asked and quickly got me involved</p>
        <p>During my time in the lab I primarily worked on two studies. The first one I worked on </p>
        <p>was called Trusting Ai or Trust In Ai (depending on who you ask.) This project is funded by NSA Crane and is still active in the lab. </p>
        <p>The main thing I contributed to this project was related to one particular study. "Hapty Bird" </p>
        <p>This study involved one outside subject and one lab member. The subject and the lab member were instructed to either </p>
        <p>play cooperativley to achieve a high score, or play against each other to achieve a high score. The cool part about this game,</p>
        <p>is that if you don't work together, you will almost always lose more money than you would working together. The game consisted</p>
        <p>of two haptic controllers in seperate rooms. Each controller controlled its own agent, but each of the two agents were tethered together.</p>
        <p>The two players were also provided with a camera to visually comunicate with the other player, but they were physically prevented from speaking to each other verbally</p>
        <p>They could only use hand gestures, emotions, and lip reading to communicate. The goal of the game is simple: make money (perhaps more than your partner.)  </p>
        <p>The participants were also told (lied to) that the money they made would be converted into real money (in gift cards) purchased by the lab. </p>
        <p>Once the game started the participants were shown the two agents, and the tehter connecting them. When one player moved their haptic feedback controller up, the other player could physically feel the pull from the agent on their hand.</p>
        <p>To make things even spicier, the gates that were shown to each player were positioned similar to flappy bird (except there are two gates you could pass through)</p>
        <p>One gate would have a net income of money while the other would have a net loss of money. however, failing to pass through either of the gates would have a huge impact on your money</p>
        <p>So players were forced to play, knowing that the "opponent" would see a chance to gain more money or chose to cooperate and potenially lose money. However if each player were to pull to the opposing gate...they would both lose a ton of money (or all of it)</p>
        <p>This study attempted to evaluate the trust between people and an autonomous agent. The study had some interesting findings, and one subject even got so mad they got up and left the lab!</p>
        <p>During the spring semester this year we presented some of the findings to the Department of Defense. We were able to show them the protocol and some of the visitors from Crane even got to play our game </p>
        <p>The main contribution I made towards this project,w as with the haptic controller code, bug fixing the code for the "hapty-bird" game, and I ran subjects through the protocol.</p>
        <p>Trusting Ai is sponsored by NSA Crane and is still currently accepting subjects</p>
        <p>---Autism Movement Study---</p>
        <p>The second study that I spent a lot of time on is called the Autism Movement study.</p>
        <p>In collaboration with researchers from IU kokomo, the Socio Neural lab is carrying out a project to study the movements/interpretations of movement of those with broad autism spectrum disorder. </p>
        <p>2 main protocols have been developed. 1 uses a kinect camera to track the movements of a participant, using point line data. The particpants were instructed to preform a series of "emotional" movements. </p>
        <p>Each of these movements were then classified by raters to determine the intensity of the emotion.</p>
        <p>This point line data is then procsessed to determine how severely the actor moved in comparrison to the baseline actors. </p>
        <p>The second protocol involves sitting in front of a computer, and following the instructions of a video on screen. The subject is show 2 videos.</p>
        <p>The first has instructions, which tells the subject to mirror the emotions they are seeing on screen, as closely as they can.</p>
        <p>The second video is a collection of baseline emotional responses. The goal of this protocol was to collect the facial affect data, and again see how the subject's emotional action units differed from the baseline'</p>
        <p> using data proccesing channels such as OpenFace and OpenCv, we were able to easily analyze the facial affects and determine with reasonable probability how people with ASD would respond versus neruo typical subjects.</p>
        <p> I was responsible for developing the protocol for the second stage (Mirroring faces exersize.) As well as taking the data collected from open face and loading it into MATLAB for proccessing.</p>
        <p>Using data analytics techniques we were able to mass process the data and pull out the desired features i,e: which facial expressions differed from the baseline the most </p>
        <p>And use this data in an attempt to try and quantify movement(s) as "Autistic" or "Neuro-Typical"</p>
        <p>It is important to note that this study is still currently in development and many of the findings are unfinished and not published. currently the lab is seeking grant funding for the study</p>
        <p> More info to come. </p>
    <!-- Add more content as needed -->
    </main>

    <!-- Footer section -->
    <footer>
        <!-- Add footer content if desired -->
    </footer>
</body>
</html>

